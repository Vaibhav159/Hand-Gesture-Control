{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import subprocess\n",
    "import os\n",
    "import webbrowser\n",
    "import ctypes\n",
    "import tensorflow as tf\n",
    "pyautogui.FAILSAFE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fist', 'five', 'four', 'one', 'three', 'two']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand=os.listdir(\"hand/train\")\n",
    "hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "classifier=tf.keras.models.load_model('hand/hand.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('hand/a.jpg', target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    guess=result.argmax()\n",
    "    return (hand[guess])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc(value):\n",
    "    for i in g:\n",
    "        if value==i:\n",
    "            g[i]+=1\n",
    "            if g[i]>=5:\n",
    "                print(g)\n",
    "                g[i]=0\n",
    "                gesture(i)\n",
    "                \n",
    "        else:\n",
    "            g[i]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture(value):\n",
    "    if value=='one':\n",
    "        subprocess.Popen([(\"C:/Program Files (x86)/VideoLAN/VLC/vlc.exe\")])\n",
    "    elif value=='two':\n",
    "        pyautogui.moveTo(c[0][0][0]*3,c[0][0][1]*3, duration = 0.1) \n",
    "    elif value=='three':\n",
    "        webbrowser.get(\"C:/Program Files (x86)/Google/Chrome/Application/chrome.exe %s\").open(\"http://google.com\")\n",
    "    elif value=='four':\n",
    "        webbrowser.get(\"C:/Program Files (x86)/Google/Chrome/Application/chrome.exe %s\").open(\"http://youtube.com\")\n",
    "    elif value=='five':\n",
    "        ctypes.windll.user32.LockWorkStation()\n",
    "    elif value=='fist':\n",
    "        pyautogui.click(x=1920,y=0,button='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(action_frame):\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "  \n",
    "    blur = cv2.GaussianBlur(action_frame, (5,5), 0)\n",
    "    hsv = cv2.cvtColor(blur, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    lower_color = np.array([108, 23, 82])\n",
    "    upper_color = np.array([179, 255, 255])\n",
    "    for (x,y,w,h) in faces:\n",
    "        hsv[y+2:y+h-2,x+2:x+w-2]=img[y+2:y+h-2,x+2:x+w-2]\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    blur = cv2.medianBlur(mask, 5)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8, 8))\n",
    "    hsv_d = cv2.dilate(blur, kernel)\n",
    "    return hsv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fist': 0, 'five': 0, 'four': 0, 'one': 0, 'three': 5, 'two': 0}\n"
     ]
    }
   ],
   "source": [
    "g={'fist':0, 'five':0, 'four':0, 'one':0, 'three':0, 'two':0}\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = np.zeros([1920,1080,1],dtype=np.uint8)\n",
    "cap=cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL) \n",
    "cv2.resizeWindow(\"output\", 1920, 1080)\n",
    "run=0\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    run=run+1\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "    \n",
    "    hsv=preprocess(frame)\n",
    "    contours,_=cv2.findContours(hsv,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    n=len(contours)\n",
    "    contours=sorted(contours,key=cv2.contourArea,reverse=False)[:n]\n",
    "    for c in contours:\n",
    "        hull=cv2.convexHull(c)\n",
    "        area=cv2.contourArea(c)\n",
    "        if area >5000:\n",
    "            cv2.drawContours(frame,[hull],0,(0,255,0),2)\n",
    "            cv2.imwrite(\"hand/a.jpg\",hsv)\n",
    "            name=pred()\n",
    "            inc(name)\n",
    "            cv2.putText(frame, name, (400,100), cv2.FONT_HERSHEY_SIMPLEX,3, (0,0,255), 2, cv2.LINE_AA)\n",
    "            pyautogui.moveTo(c[0][0][0]*3,c[0][0][1]*3, duration = 0.1) \n",
    "    \n",
    "    cv2.imshow(\"output\",frame)\n",
    "    \n",
    "    cv2.imshow(\"mask\",hsv)\n",
    "    if cv2.waitKey(100) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
